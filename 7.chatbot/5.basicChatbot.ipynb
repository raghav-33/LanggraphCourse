{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e80ebaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict , Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import BaseMessage ,SystemMessage,HumanMessage,AIMessage\n",
    "\n",
    "# Persistance Import\n",
    "from langgraph.checkpoint.memory import MemorySaver  #kind of memory in langraph which store things in RAM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb73699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Define\n",
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages ]  # Base Messages : all types of messages is derived from it , it indicate here any type of message can be present either human , AI or system message\n",
    "\n",
    "# add_messages: is a reducer function like operator.add in previous code.\n",
    "# Why ?\n",
    "# Because nature of state is when it get new value its old value (message) is deleted .\n",
    "# therefore add_messages (reducer function) is  used to maintain conversational history, not forget previous messages or states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM define\n",
    "llm = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9815ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "    # Take User Query From state\n",
    "    messages = state['messages']\n",
    "\n",
    "    # Send to llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Response store state\n",
    "    return {'messages' : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697ea0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Define\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# nodes add\n",
    "graph.add_node('chat_node', chat_node)\n",
    "\n",
    "# Edge add\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "# Compile\n",
    "chatbot = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23110df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Graph\n",
    "initial_state = {\n",
    "    'messages' : [HumanMessage(content = \"What is Capital of India\")]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bea7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot Logic\n",
    "while True:\n",
    "    user_message = input('Type Here')\n",
    "\n",
    "    print(\"User:\" , user_message)\n",
    "\n",
    "    if user_message.strip().lower() in ['exit', 'quit' , 'bye']:\n",
    "        break\n",
    "    response= chatbot.invoke({'messages': [HumanMessage(content=user_message)]})\n",
    "    \n",
    "    print('AI:', response['messages'[-1].content])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70238276",
   "metadata": {},
   "source": [
    "Normally\n",
    "when we reach at end of workflow , our state get erased . every time when we newly invoke (workflow) ,newly state start\n",
    "\n",
    "\n",
    "But in Persistence\n",
    "at end of workflow state not get erased and we store it in various places like Databases , memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44087528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict , Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import BaseMessage ,SystemMessage,HumanMessage,AIMessage\n",
    "\n",
    "# Persistance Import\n",
    "from langgraph.checkpoint.memory import MemorySaver  #kind of memory in langraph which store things in RAM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15802dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Define\n",
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages ]  # Base Messages : all types of messages is derived from it , it indicate here any type of message can be present either human , AI or system message\n",
    "\n",
    "# add_messages: is a reducer function like operator.add in previous code.\n",
    "# Why ?\n",
    "# Because nature of state is when it get new value its old value (message) is deleted .\n",
    "# therefore add_messages (reducer function) is  used to maintain conversational history, not forget previous messages or states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a68715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM define\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b8364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "    # Take User Query From state\n",
    "    messages = state['messages']\n",
    "\n",
    "    # Send to llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Response store state\n",
    "    return {'messages' : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25d8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Define\n",
    "\n",
    "checkpointer = MemorySaver()  # Persistance : memory\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# nodes add\n",
    "graph.add_node('chat_node', chat_node)\n",
    "\n",
    "# Edge add\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "# Compile\n",
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Graph\n",
    "initial_state = {\n",
    "    'messages' : [HumanMessage(content = \"What is Capital of India\")]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot Logic\n",
    "thread_id= '1' # Basically at same time chatbot is used by many peoples . so thread id is chatbot kis people sai kya baat kr rha hai.\n",
    "while True:\n",
    "    user_message = input('Type Here')\n",
    "\n",
    "    print(\"User:\" , user_message)\n",
    "\n",
    "    if user_message.strip().lower() in ['exit', 'quit' , 'bye']:\n",
    "        break\n",
    "\n",
    "    config = {'configurable': {'thread_id':thread_id}}\n",
    "    response= chatbot.invoke({'messages': [HumanMessage(content=user_message)]},config=config)\n",
    "    \n",
    "    print('AI:', response['messages'[-1].content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view all converstional History\n",
    "chatbot.get_state(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
