{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836c413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START , END\n",
    "from typing import TypedDict , Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Tools node and Tool conditions\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool  # for Custom tool\n",
    "\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Tools\n",
    "''' In Langchain 2 types of Tool (i) Prebuilt  (ii) Custom:Created By user and defined with @tool decorator'''\n",
    "\n",
    "search_tool = DuckDuckGoSearchRun(region=\"us-en\")  #prebuilt Tool\n",
    "\n",
    "#Custom tool\n",
    "@tool\n",
    "def calculator(first_num: float , second_num: float , operation: str) ->dict:\n",
    "    \"\"\"\n",
    "    Perform a basic airthmetic Operation on Two Numbers.\n",
    "    Supported Operations: add,sub,mul,div.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if operation == \"add\":\n",
    "            result = first_num+second_num\n",
    "        elif operation == \"sub\":\n",
    "            result = first_num-second_num\n",
    "        elif operation == \"mul\":\n",
    "            result = first_num*second_num\n",
    "        elif operation == \"div\":\n",
    "            if second_num == 0:\n",
    "                return {'error' : 'Division by Zero is not allowed'}\n",
    "            result = first_num/second_num\n",
    "        else:\n",
    "            return {\"error\" : f\"unsupported Operation '{operation}' \"}\n",
    "\n",
    "        return {\"first_num \":first_num ,\"second_num\":second_num,\"operation\":operation,\"result\":result}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'error':str(e)}\n",
    "    \n",
    "@tool\n",
    "def get_stock_price(symbol: str) ->dict:\n",
    "    \"\"\" Fetch the latest stock price for a given symbol (eg. 'AAPL' ,'TSLA') \n",
    "        using Alpha vintage With Api key in the URl.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={symbol}&apikey=C9PE94QUEW9VWGFM\"\n",
    "    r= requests.get(url)\n",
    "    return r.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc34984",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tool List\n",
    "tool= [get_stock_price,search_tool,calculator]\n",
    "\n",
    "# Make the LLM tool aware\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2717f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class ChatState(TypedDict):\n",
    "    messages:Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd51a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Node Functions\n",
    "\n",
    "# Chat Node\n",
    "def chat_node(state: ChatState):\n",
    "    \"\"\"LLM node that may Answer or request a tool call.\"\"\"\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\" :[response]}\n",
    "\n",
    "# Tool Node\n",
    "tool_node=ToolNode(tools) # Execute tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph define\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# Nodes\n",
    "graph.add_node('chat_node',chat_node)\n",
    "graph.add_node('tool_node',tool_node)\n",
    "\n",
    "# Edges\n",
    "graph.add_edge(START,'chat_node')\n",
    "# If LLM ask for a tool go to ToolNode; else Finish\n",
    "graph.add_conditional_edges(\"chat_node\",tools_condition)\n",
    "\n",
    "# Compile graph\n",
    "chatbot = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Chat\n",
    "out = chatbot.invoke({'messages':[HumanMessage(content =\"hello\")]})\n",
    "print(out['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e987f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat requiring tool\n",
    "out = chatbot.invoke({'messages':[HumanMessage(content =\"what is stock price of apple\")]})\n",
    "print(out['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cabf22",
   "metadata": {},
   "source": [
    "Problem is Now ?\n",
    "\n",
    "(i) Output of Tools is usually not a refines so we can directly \n",
    "display to user , but our desgined workflow is after going to \n",
    "tool node directly go to end node , not refining a output.\n",
    "\n",
    "(ii) For MultiStep Tool usage Involvement Query (like using \n",
    "tool 2 time in single query) result is not coming , since after \n",
    "going first time from chatNode to ToolNode it is directly going \n",
    "to End Node\n",
    "\n",
    "example : Multi Step Tool Query\n",
    "\n",
    "What is the stock price of apple today and how much it cost if \n",
    "buy a 70 stock?\n",
    "\n",
    "1st Step : Stock Tool Use: Find Price\n",
    "\n",
    "2nd Step : Calculator Tool use: Multiply Stock price with 70\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d99095d",
   "metadata": {},
   "source": [
    "Now Our WorkFlow is Modified from\n",
    "instead of directly Going from (i) chatNode to End and From (ii) ChatNode to {ToolNode to End}\n",
    "\n",
    "Now From (i) ToolNode Going Back to ChatNode and (ii) from chatNode to End\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff8198",
   "metadata": {},
   "source": [
    "Remaining Code is Same Only Workflow code changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph define\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# Nodes\n",
    "graph.add_node('chat_node',chat_node)\n",
    "graph.add_node('tool_node',tool_node)\n",
    "\n",
    "# Edges\n",
    "graph.add_edge(START,'chat_node')\n",
    "# If LLM ask for a tool go to ToolNode; else Finish\n",
    "graph.add_conditional_edges(\"chat_node\",tools_condition)\n",
    "# Changed add\n",
    "graph.add_edge(\"tools\" , \"chat_node\")\n",
    "\n",
    "# Compile graph\n",
    "chatbot = graph.compile()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
